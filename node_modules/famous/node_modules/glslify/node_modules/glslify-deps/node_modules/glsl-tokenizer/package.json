{
  "name": "glsl-tokenizer",
  "version": "1.1.1",
  "description": "r/w stream of glsl tokens",
  "main": "stream.js",
  "directories": {
    "test": "test"
  },
  "authors": [
    "Hugh Kennedy <hughskennedy@gmail.com> (http://hughsk.io/)",
    "Mikola Lysenko <mikolalysenko@gmail.com> (http://0fps.net)",
    "Chris Dickinson <chris@neversaw.us> (http://neversaw.us)"
  ],
  "scripts": {
    "test": "node test/index.js | tap-spec"
  },
  "repository": {
    "type": "git",
    "url": "git://github.com/gl-modules/glsl-tokenizer.git"
  },
  "keywords": [
    "glsl",
    "tokenizer",
    "stream"
  ],
  "author": {
    "name": "Chris Dickinson",
    "email": "chris@neversaw.us"
  },
  "license": "MIT",
  "dependencies": {
    "through2": "^0.6.3"
  },
  "devDependencies": {
    "tap-spec": "^1.0.1",
    "tape": "^3.0.2"
  },
  "gitHead": "1e1196d40e446d1e4b02fac7b75acf80b71072d6",
  "readme": "# glsl-tokenizer\r\n\r\nMaps GLSL string data into GLSL tokens, either synchronously or using a\r\nstreaming API.\r\n\r\n``` javascript\r\nvar tokenString = require('glsl-tokenizer/string')\r\nvar tokenStream = require('glsl-tokenizer/stream')\r\nvar fs = require('fs')\r\n\r\n// Synchronously:\r\nvar tokens = tokenString(fs.readFileSync('some.glsl'))\r\n\r\n// Streaming API:\r\nfs.createReadStream('some.glsl')\r\n  .pipe(tokenStream())\r\n  .on('data', function(token) {\r\n    console.log(token.data, token.position, token.type)\r\n  })\r\n```\r\n\r\n# API\r\n\r\n## tokens = require('glsl-tokenizer/string')(src)\r\n\r\nReturns an array of `tokens` given the GLSL source string `src`\r\n\r\n## stream = require('glsl-tokenizer/stream')()\r\n\r\nEmits 'data' events whenever a token is parsed with a token object as output.\r\n\r\n# Tokens\r\n\r\n```javascript\r\n{ 'type': TOKEN_TYPE\r\n, 'data': \"string of constituent data\"\r\n, 'position': integer position within the GLSL source\r\n, 'line': line number within the GLSL source\r\n, 'column': column number within the GLSL source }\r\n```\r\n\r\nThe available token types are:\r\n\r\n* `block-comment`: `/* ... */`\r\n* `line-comment`: `// ... \\n`\r\n* `preprocessor`: `# ... \\n`\r\n* `operator`: Any operator. If it looks like punctuation, it's an operator.\r\n* `float`: Optionally suffixed with `f`\r\n* `ident`: User defined identifier.\r\n* `builtin`: Builtin function.\r\n* `eof`: Emitted on `end`; data will === `'(eof)'`.\r\n* `integer`\r\n* `whitespace`\r\n* `keyword`\r\n\r\n# License\r\n\r\nMIT, see [LICENSE.md](LICENSE.md) for further information.\r\n",
  "readmeFilename": "README.md",
  "bugs": {
    "url": "https://github.com/gl-modules/glsl-tokenizer/issues"
  },
  "homepage": "https://github.com/gl-modules/glsl-tokenizer#readme",
  "_id": "glsl-tokenizer@1.1.1",
  "_shasum": "978372e777c1a8b1374e05a81eb066bf688abaef",
  "_from": "git://github.com/stackgl/glsl-tokenizer.git#2.0.0",
  "_resolved": "git://github.com/stackgl/glsl-tokenizer.git#1e1196d40e446d1e4b02fac7b75acf80b71072d6"
}
